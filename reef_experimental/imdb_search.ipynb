{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "\n",
    "from imdb_lstm import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np.load('/dfs/scratch0/paroma/data/imdb/lstm_train_ground.npy')\n",
    "y_train = np.load('/dfs/scratch0/paroma/reef/imdb_reef_dt1.npy')\n",
    "\n",
    "train_text = np.load('/dfs/scratch0/paroma/data/imdb/lstm_train_text.npy')\n",
    "test_text = np.load('/dfs/scratch0/paroma/data/imdb/lstm_val_text.npy')\n",
    "y_test = np.load('/dfs/scratch0/paroma/data/imdb/lstm_val_ground.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           225536    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 278,837\n",
      "Trainable params: 278,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1136 samples, validate on 284 samples\n",
      "Epoch 1/5\n",
      "1136/1136 [==============================] - 15s 13ms/step - loss: 0.6864 - acc: 0.0000e+00 - val_loss: 0.6915 - val_acc: 0.5458\n",
      "Epoch 2/5\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6833 - acc: 0.0000e+00 - val_loss: 0.6936 - val_acc: 0.5458\n",
      "Epoch 3/5\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6722 - acc: 0.0000e+00 - val_loss: 0.7235 - val_acc: 0.4577\n",
      "Epoch 4/5\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6409 - acc: 0.0000e+00 - val_loss: 0.7512 - val_acc: 0.5106\n",
      "Epoch 5/5\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6210 - acc: 0.0000e+00 - val_loss: 0.7232 - val_acc: 0.5317\n",
      "Accuracy: 53.17%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 32)           225536    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 278,837\n",
      "Trainable params: 278,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1136 samples, validate on 284 samples\n",
      "Epoch 1/10\n",
      "1136/1136 [==============================] - 15s 13ms/step - loss: 0.6885 - acc: 0.0000e+00 - val_loss: 0.6899 - val_acc: 0.5458\n",
      "Epoch 2/10\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6837 - acc: 0.0000e+00 - val_loss: 0.6903 - val_acc: 0.5458\n",
      "Epoch 3/10\n",
      "1136/1136 [==============================] - 14s 13ms/step - loss: 0.6781 - acc: 0.0000e+00 - val_loss: 0.7101 - val_acc: 0.5458\n",
      "Epoch 4/10\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6549 - acc: 0.0000e+00 - val_loss: 0.7106 - val_acc: 0.4296\n",
      "Epoch 5/10\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6352 - acc: 0.0000e+00 - val_loss: 0.7241 - val_acc: 0.4542\n",
      "Epoch 6/10\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6203 - acc: 0.0000e+00 - val_loss: 0.7415 - val_acc: 0.4718\n",
      "Epoch 7/10\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6116 - acc: 0.0000e+00 - val_loss: 0.7447 - val_acc: 0.4789\n",
      "Epoch 8/10\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6068 - acc: 0.0000e+00 - val_loss: 0.7453 - val_acc: 0.4718\n",
      "Epoch 9/10\n",
      "1136/1136 [==============================] - 15s 13ms/step - loss: 0.6040 - acc: 0.0000e+00 - val_loss: 0.7441 - val_acc: 0.4648\n",
      "Epoch 10/10\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6026 - acc: 0.0000e+00 - val_loss: 0.7477 - val_acc: 0.4789\n",
      "Accuracy: 47.89%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 32)           225536    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 278,837\n",
      "Trainable params: 278,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1136 samples, validate on 284 samples\n",
      "Epoch 1/25\n",
      "1136/1136 [==============================] - 16s 14ms/step - loss: 0.6871 - acc: 0.0000e+00 - val_loss: 0.6908 - val_acc: 0.5458\n",
      "Epoch 2/25\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6831 - acc: 0.0000e+00 - val_loss: 0.6943 - val_acc: 0.5458\n",
      "Epoch 3/25\n",
      "1136/1136 [==============================] - 14s 13ms/step - loss: 0.6645 - acc: 0.0000e+00 - val_loss: 0.7302 - val_acc: 0.5106\n",
      "Epoch 4/25\n",
      "1136/1136 [==============================] - 14s 13ms/step - loss: 0.6345 - acc: 0.0000e+00 - val_loss: 0.7437 - val_acc: 0.5070\n",
      "Epoch 5/25\n",
      "1136/1136 [==============================] - 14s 13ms/step - loss: 0.6179 - acc: 0.0000e+00 - val_loss: 0.7300 - val_acc: 0.5211\n",
      "Epoch 6/25\n",
      "1136/1136 [==============================] - 14s 13ms/step - loss: 0.6099 - acc: 0.0000e+00 - val_loss: 0.7524 - val_acc: 0.5282\n",
      "Epoch 7/25\n",
      "1136/1136 [==============================] - 15s 13ms/step - loss: 0.6060 - acc: 0.0000e+00 - val_loss: 0.7513 - val_acc: 0.5106\n",
      "Epoch 8/25\n",
      "1136/1136 [==============================] - 15s 13ms/step - loss: 0.6035 - acc: 0.0000e+00 - val_loss: 0.7568 - val_acc: 0.4965\n",
      "Epoch 9/25\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6021 - acc: 0.0000e+00 - val_loss: 0.7625 - val_acc: 0.5000\n",
      "Epoch 10/25\n",
      "1136/1136 [==============================] - 14s 13ms/step - loss: 0.6010 - acc: 0.0000e+00 - val_loss: 0.7593 - val_acc: 0.4930\n",
      "Epoch 11/25\n",
      "1136/1136 [==============================] - 16s 14ms/step - loss: 0.6005 - acc: 0.0000e+00 - val_loss: 0.7616 - val_acc: 0.4894\n",
      "Epoch 12/25\n",
      "1136/1136 [==============================] - 15s 13ms/step - loss: 0.6000 - acc: 0.0000e+00 - val_loss: 0.7640 - val_acc: 0.4789\n",
      "Epoch 13/25\n",
      "1136/1136 [==============================] - 14s 13ms/step - loss: 0.5998 - acc: 0.0000e+00 - val_loss: 0.7557 - val_acc: 0.4789\n",
      "Epoch 14/25\n",
      "1136/1136 [==============================] - 14s 13ms/step - loss: 0.6001 - acc: 0.0000e+00 - val_loss: 0.7680 - val_acc: 0.4930\n",
      "Epoch 15/25\n",
      "1136/1136 [==============================] - 16s 14ms/step - loss: 0.5999 - acc: 0.0000e+00 - val_loss: 0.7644 - val_acc: 0.4965\n",
      "Epoch 16/25\n",
      "1136/1136 [==============================] - 14s 13ms/step - loss: 0.5997 - acc: 0.0000e+00 - val_loss: 0.7619 - val_acc: 0.4718\n",
      "Epoch 17/25\n",
      "1136/1136 [==============================] - 14s 13ms/step - loss: 0.5997 - acc: 0.0000e+00 - val_loss: 0.7539 - val_acc: 0.4754\n",
      "Epoch 18/25\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.5992 - acc: 0.0000e+00 - val_loss: 0.7592 - val_acc: 0.4894\n",
      "Epoch 19/25\n",
      "1136/1136 [==============================] - 15s 13ms/step - loss: 0.5990 - acc: 0.0000e+00 - val_loss: 0.7593 - val_acc: 0.4824\n",
      "Epoch 20/25\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.5990 - acc: 0.0000e+00 - val_loss: 0.7624 - val_acc: 0.4789\n",
      "Epoch 21/25\n",
      "1136/1136 [==============================] - 15s 13ms/step - loss: 0.5988 - acc: 0.0000e+00 - val_loss: 0.7578 - val_acc: 0.4930\n",
      "Epoch 22/25\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.5987 - acc: 0.0000e+00 - val_loss: 0.7576 - val_acc: 0.4859\n",
      "Epoch 23/25\n",
      "1136/1136 [==============================] - 16s 14ms/step - loss: 0.5986 - acc: 0.0000e+00 - val_loss: 0.7603 - val_acc: 0.4859\n",
      "Epoch 24/25\n",
      "1136/1136 [==============================] - 16s 14ms/step - loss: 0.5986 - acc: 0.0000e+00 - val_loss: 0.7612 - val_acc: 0.4754\n",
      "Epoch 25/25\n",
      "1136/1136 [==============================] - 15s 14ms/step - loss: 0.5986 - acc: 0.0000e+00 - val_loss: 0.7562 - val_acc: 0.4930\n",
      "Accuracy: 49.30%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 32)           225536    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 278,837\n",
      "Trainable params: 278,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1136 samples, validate on 284 samples\n",
      "Epoch 1/5\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6900 - acc: 0.0000e+00 - val_loss: 0.6903 - val_acc: 0.5458\n",
      "Epoch 2/5\n",
      "1136/1136 [==============================] - 13s 12ms/step - loss: 0.6852 - acc: 0.0000e+00 - val_loss: 0.6897 - val_acc: 0.5458\n",
      "Epoch 3/5\n",
      "1136/1136 [==============================] - 13s 12ms/step - loss: 0.6829 - acc: 0.0000e+00 - val_loss: 0.6923 - val_acc: 0.5458\n",
      "Epoch 4/5\n",
      "1136/1136 [==============================] - 13s 12ms/step - loss: 0.6778 - acc: 0.0000e+00 - val_loss: 0.6961 - val_acc: 0.5458\n",
      "Epoch 5/5\n",
      "1136/1136 [==============================] - 13s 12ms/step - loss: 0.6586 - acc: 0.0000e+00 - val_loss: 0.7460 - val_acc: 0.5000\n",
      "Accuracy: 50.00%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 500, 32)           225536    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 278,837\n",
      "Trainable params: 278,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1136 samples, validate on 284 samples\n",
      "Epoch 1/10\n",
      "1136/1136 [==============================] - 14s 12ms/step - loss: 0.6894 - acc: 0.0000e+00 - val_loss: 0.6904 - val_acc: 0.5458\n",
      "Epoch 2/10\n",
      "1136/1136 [==============================] - 13s 12ms/step - loss: 0.6842 - acc: 0.0000e+00 - val_loss: 0.6904 - val_acc: 0.5458\n",
      "Epoch 3/10\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.6818 - acc: 0.0000e+00 - val_loss: 0.6912 - val_acc: 0.5458\n",
      "Epoch 4/10\n",
      "1136/1136 [==============================] - 13s 12ms/step - loss: 0.6743 - acc: 0.0000e+00 - val_loss: 0.7002 - val_acc: 0.5458\n",
      "Epoch 5/10\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.6496 - acc: 0.0000e+00 - val_loss: 0.7330 - val_acc: 0.4824\n",
      "Epoch 6/10\n",
      "1136/1136 [==============================] - 13s 12ms/step - loss: 0.6319 - acc: 0.0000e+00 - val_loss: 0.7265 - val_acc: 0.4683\n",
      "Epoch 7/10\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.6206 - acc: 0.0000e+00 - val_loss: 0.7333 - val_acc: 0.4789\n",
      "Epoch 8/10\n",
      "1136/1136 [==============================] - 12s 11ms/step - loss: 0.6120 - acc: 0.0000e+00 - val_loss: 0.7320 - val_acc: 0.4930\n",
      "Epoch 9/10\n",
      "1136/1136 [==============================] - 12s 10ms/step - loss: 0.6070 - acc: 0.0000e+00 - val_loss: 0.7370 - val_acc: 0.4965\n",
      "Epoch 10/10\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.6043 - acc: 0.0000e+00 - val_loss: 0.7469 - val_acc: 0.4930\n",
      "Accuracy: 49.30%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 500, 32)           225536    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 278,837\n",
      "Trainable params: 278,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1136 samples, validate on 284 samples\n",
      "Epoch 1/25\n",
      "1136/1136 [==============================] - 13s 12ms/step - loss: 0.6894 - acc: 0.0000e+00 - val_loss: 0.6891 - val_acc: 0.5458\n",
      "Epoch 2/25\n",
      "1136/1136 [==============================] - 12s 11ms/step - loss: 0.6852 - acc: 0.0000e+00 - val_loss: 0.6890 - val_acc: 0.5458\n",
      "Epoch 3/25\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.6828 - acc: 0.0000e+00 - val_loss: 0.6900 - val_acc: 0.5458\n",
      "Epoch 4/25\n",
      "1136/1136 [==============================] - 12s 11ms/step - loss: 0.6779 - acc: 0.0000e+00 - val_loss: 0.6950 - val_acc: 0.5458\n",
      "Epoch 5/25\n",
      "1136/1136 [==============================] - 12s 11ms/step - loss: 0.6633 - acc: 0.0000e+00 - val_loss: 0.7068 - val_acc: 0.4859\n",
      "Epoch 6/25\n",
      "1136/1136 [==============================] - 12s 11ms/step - loss: 0.6373 - acc: 0.0000e+00 - val_loss: 0.7393 - val_acc: 0.5035\n",
      "Epoch 7/25\n",
      "1136/1136 [==============================] - 12s 11ms/step - loss: 0.6250 - acc: 0.0000e+00 - val_loss: 0.7339 - val_acc: 0.5141\n",
      "Epoch 8/25\n",
      "1136/1136 [==============================] - 12s 11ms/step - loss: 0.6160 - acc: 0.0000e+00 - val_loss: 0.7426 - val_acc: 0.5035\n",
      "Epoch 9/25\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.6098 - acc: 0.0000e+00 - val_loss: 0.7471 - val_acc: 0.5141\n",
      "Epoch 10/25\n",
      "1136/1136 [==============================] - 12s 11ms/step - loss: 0.6064 - acc: 0.0000e+00 - val_loss: 0.7460 - val_acc: 0.5106\n",
      "Epoch 11/25\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.6042 - acc: 0.0000e+00 - val_loss: 0.7491 - val_acc: 0.5106\n",
      "Epoch 12/25\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.6026 - acc: 0.0000e+00 - val_loss: 0.7446 - val_acc: 0.4965\n",
      "Epoch 13/25\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.6015 - acc: 0.0000e+00 - val_loss: 0.7493 - val_acc: 0.4894\n",
      "Epoch 14/25\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.6007 - acc: 0.0000e+00 - val_loss: 0.7480 - val_acc: 0.5035\n",
      "Epoch 15/25\n",
      "1136/1136 [==============================] - 12s 11ms/step - loss: 0.5999 - acc: 0.0000e+00 - val_loss: 0.7540 - val_acc: 0.5035\n",
      "Epoch 16/25\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.5997 - acc: 0.0000e+00 - val_loss: 0.7536 - val_acc: 0.4965\n",
      "Epoch 17/25\n",
      "1136/1136 [==============================] - 13s 12ms/step - loss: 0.5994 - acc: 0.0000e+00 - val_loss: 0.7532 - val_acc: 0.4965\n",
      "Epoch 18/25\n",
      "1136/1136 [==============================] - 13s 11ms/step - loss: 0.5993 - acc: 0.0000e+00 - val_loss: 0.7519 - val_acc: 0.5000\n",
      "Epoch 19/25\n",
      " 768/1136 [===================>..........] - ETA: 3s - loss: 0.6007 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "f1_all = []\n",
    "pr_all = []\n",
    "re_all = []\n",
    "val_acc_all = []\n",
    "\n",
    "\n",
    "bs_arr = [64,128,256]\n",
    "n_epochs_arr = [5,10,25]\n",
    "\n",
    "for bs in bs_arr:\n",
    "    for n in n_epochs_arr:\n",
    "        y_pred = lstm_simple(train_text, y_train, test_text, y_test, bs=bs, n=n)\n",
    "        predictions = np.round(y_pred)\n",
    "        #labels_flipped = np.abs(1-np.round(y_pred))\n",
    "        \n",
    "        val_acc_all.append(np.sum(predictions == labels)/float(np.shape(labels)[0]))\n",
    "        f1_all.append(metrics.f1_score(y_test, predictions))\n",
    "        pr_all.append(metrics.precision_score(y_test, predictions))\n",
    "        re_all.append(metrics.recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii,jj,kk = np.unravel_index(np.argmax(f1_all), (3,3))\n",
    "print 'Best Batch Size: ', bs_arr[ii]\n",
    "print 'Best Epochs: ', n_epochs_arr[jj]\n",
    "print 'F1 Score: ', max(f1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Best Val Acc: ', np.max(val_acc_all)\n",
    "print '\\nBest F1: ', np.max(f1_all)\n",
    "print 'Best Pr: ', pr_all[np.argmax(f1_all)]\n",
    "print 'Best Re: ', re_all[np.argmax(f1_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
